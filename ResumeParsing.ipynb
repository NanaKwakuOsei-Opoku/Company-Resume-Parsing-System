{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pdfplumber\n",
    "import pytesseract\n",
    "import fitz  \n",
    "from PIL import Image\n",
    "import io\n",
    "\n",
    "def extract_text_from_pdf(pdf_path):\n",
    "    text = \"\"\n",
    "    try:\n",
    "        with pdfplumber.open(pdf_path) as pdf:\n",
    "            for page in pdf.pages:\n",
    "                page_text = page.extract_text()\n",
    "                if page_text:\n",
    "                    text += page_text + \"\\n\"\n",
    "    except Exception as e:\n",
    "        print(\"Error using pdfplumber:\", e)\n",
    "\n",
    "    # If no text is found, try OCR with PyMuPDF and pytesseract\n",
    "    if not text.strip():\n",
    "        try:\n",
    "            doc = fitz.open(pdf_path)\n",
    "            for page in doc:\n",
    "                pix = page.get_pixmap()\n",
    "                img = Image.open(io.BytesIO(pix.tobytes()))\n",
    "                text += pytesseract.image_to_string(img) + \"\\n\"\n",
    "        except Exception as e:\n",
    "            print(\"Error using OCR:\", e)\n",
    "    return text.strip()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "import re\n",
    "from fuzzywuzzy import process\n",
    "\n",
    "# Load spaCy NLP model\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "def extract_name(text):\n",
    "    doc = nlp(text)\n",
    "    for ent in doc.ents:\n",
    "        if ent.label_ == \"PERSON\":\n",
    "            return ent.text\n",
    "    return \"Unknown\"\n",
    "\n",
    "def extract_contact_info(text):\n",
    "    email = re.findall(r\"[a-zA-Z0-9+_.-]+@[a-zA-Z0-9.-]+\", text)\n",
    "    phone = re.findall(r\"\\+?\\d[\\d -]{8,}\\d\", text)\n",
    "    return {\"email\": email[0] if email else \"Not found\", \"phone\": phone[0] if phone else \"Not found\"}\n",
    "\n",
    "def extract_skills(text, skills_list):\n",
    "    found_skills = []\n",
    "    for skill in skills_list:\n",
    "        if skill.lower() in text.lower():\n",
    "            found_skills.append(skill)\n",
    "        elif process.extractOne(skill, text.split(), score_cutoff=80):\n",
    "            found_skills.append(skill)\n",
    "    return list(set(found_skills))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dateutil import parser\n",
    "import re\n",
    "\n",
    "def extract_experience(text):\n",
    "    # Extract all four-digit years from the text\n",
    "    years = re.findall(r\"\\b(19|20)\\d{2}\\b\", text)\n",
    "    if len(years) >= 2:\n",
    "        start_year, end_year = int(years[0]), int(years[-1])\n",
    "        total_exp = end_year - start_year\n",
    "    else:\n",
    "        total_exp = 0\n",
    "    return total_exp\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Match Score: 0.7666666666666666\n"
     ]
    }
   ],
   "source": [
    "def match_candidate(candidate, job_req):\n",
    "    skill_match = len(set(candidate[\"skills\"]).intersection(set(job_req[\"skills\"]))) / len(job_req[\"skills\"])\n",
    "    exp_match = 1 if candidate[\"experience\"] >= job_req[\"min_experience\"] else 0\n",
    "    score = (skill_match * 0.7) + (exp_match * 0.3)\n",
    "    return score\n",
    "\n",
    "# Example candidate and job requirement\n",
    "candidate = {\n",
    "    \"skills\": [\"Python\", \"SQL\", \"Data Science\"],\n",
    "    \"experience\": 10\n",
    "}\n",
    "job_requirements = {\n",
    "    \"skills\": [\"Python\", \"Machine Learning\", \"SQL\"],\n",
    "    \"min_experience\": 3\n",
    "}\n",
    "\n",
    "print(\"Match Score:\", match_candidate(candidate, job_requirements))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'skills': ['Python', 'Machine Learning', 'SQL'], 'experience': 5}, {'skills': ['Python', 'SQL'], 'experience': 10}, {'skills': ['Java', 'SQL'], 'experience': 4}]\n"
     ]
    }
   ],
   "source": [
    "def rank_candidates(candidates, job_req):\n",
    "    ranked = sorted(candidates, key=lambda c: match_candidate(c, job_req), reverse=True)\n",
    "    return ranked[:5]  # Returns top 5 candidates\n",
    "\n",
    "# Example usage with a list of candidate dictionaries:\n",
    "candidates_list = [\n",
    "    {\"skills\": [\"Python\", \"SQL\"], \"experience\": 10},\n",
    "    {\"skills\": [\"Python\", \"Machine Learning\", \"SQL\"], \"experience\": 5},\n",
    "    {\"skills\": [\"Java\", \"SQL\"], \"experience\": 4},\n",
    "]\n",
    "top_candidates = rank_candidates(candidates_list, job_requirements)\n",
    "print(top_candidates)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
